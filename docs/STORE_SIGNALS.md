# Signals Storage System

Signals table introduced in Phase 13.0 for streaming inference signals.

## Overview

The signals storage system provides high-performance, idempotent storage for real-time inference signals generated by the streaming pipeline. It's designed to handle high-volume signal ingestion with TimescaleDB optimization.

## Schema

### Primary Key
- **Composite Key**: `(provider, symbol, ts, name)`
- **Purpose**: Ensures unique signals per provider/symbol/timestamp/name combination
- **Benefits**: Enables idempotent upserts and efficient querying

### Table Structure

```sql
CREATE TABLE signals (
    provider  TEXT NOT NULL,
    symbol    TEXT NOT NULL CHECK (symbol = UPPER(symbol)),
    ts        TIMESTAMPTZ NOT NULL,
    name      TEXT NOT NULL,
    value     DOUBLE PRECISION NOT NULL,
    score     DOUBLE PRECISION,
    metadata  JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    PRIMARY KEY (provider, symbol, ts, name)
);
```

### TimescaleDB Features

- **Hypertable**: Partitioned by time with 7-day chunks
- **Compression**: 30-day hot tier with segment-by `(provider, symbol, name)`
- **Indexes**: Optimized for common query patterns
  - `(provider, symbol, name, ts DESC)` - Latest signals per symbol
  - `(ts DESC)` - Time-based queries
  - `(name, ts DESC)` - Signal type queries

## Client APIs

### SignalsStoreClient (Sync)

```python
from datastore import SignalsStoreClient

# Context manager usage
with SignalsStoreClient(uri) as client:
    signals = [
        SimpleNamespace(
            provider="ibkr_primary",
            symbol="SPY",
            ts=datetime.now(timezone.utc),
            name="vwap_cross_up",
            value=1.0,
            score=0.85,
            metadata={"window": "1m", "price": 425.15}
        )
    ]

    written_count = client.write_signals(signals)
    print(f"Wrote {written_count} signals")
```

### AsyncSignalsStoreClient (Async)

```python
from datastore import AsyncSignalsStoreClient

async with AsyncSignalsStoreClient(uri) as client:
    written_count = await client.write_signals(signals)
    print(f"Wrote {written_count} signals")
```

### SignalsQueryClient (Sync)

```python
from datastore import SignalsQueryClient

with SignalsQueryClient(uri) as client:
    # Latest signals for a symbol
    latest = client.get_latest_signals("ibkr_primary", "SPY", limit=10)

    # Signal history
    history = client.get_signals_history(
        "ibkr_primary", "SPY",
        start_ts=datetime.now() - timedelta(hours=1),
        end_ts=datetime.now()
    )

    # Signal metrics
    metrics = client.get_signal_metrics("ibkr_primary", "SPY", "vwap_cross_up")

    # Active signals (last 5 minutes)
    active = client.get_active_signals("ibkr_primary", minutes_back=5)

    # Summary statistics
    summary = client.get_signal_summary("ibkr_primary", hours_back=24)
```

## Performance Features

### Idempotent Upserts

The system uses diff-aware upserts to ensure idempotency:

```sql
INSERT INTO signals (provider, symbol, ts, name, value, score, metadata)
VALUES ($1, $2, $3, $4, $5, $6, $7)
ON CONFLICT (provider, symbol, ts, name)
DO UPDATE SET
    value = EXCLUDED.value,
    score = EXCLUDED.score,
    metadata = EXCLUDED.metadata
WHERE
    signals.value IS DISTINCT FROM EXCLUDED.value OR
    signals.score IS DISTINCT FROM EXCLUDED.score OR
    signals.metadata IS DISTINCT FROM EXCLUDED.metadata
```

### Smart Batching

- **Small batches (< 1000)**: Uses `executemany` with upserts
- **Large batches (â‰¥ 1000)**: Uses `COPY` via temp table for maximum performance
- **Configurable threshold**: Adjustable via `batch_threshold` parameter

### Prometheus Metrics

Built-in observability with Prometheus metrics:

- `store_signals_written_total{method, status}` - Total signals written
- `store_signals_write_latency_seconds{method}` - Write latency histogram

## Usage Patterns

### Pipeline Integration

```python
# In market_data_pipeline streaming components
from datastore import SignalsStoreClient

class InferenceConsumer:
    def __init__(self, store_uri: str):
        self.store_client = SignalsStoreClient(store_uri)

    async def process_signals(self, signals):
        with self.store_client:
            written = self.store_client.write_signals(signals)
            logger.info(f"Stored {written} signals")
```

### Analytics Queries

```python
# In analytics/ML systems
from datastore import SignalsQueryClient

with SignalsQueryClient(uri) as client:
    # Get latest signals for ML feature engineering
    latest_signals = client.get_latest_signals(
        provider="ibkr_primary",
        symbol="SPY",
        signal_names=["vwap_cross_up", "volatility_spike"]
    )

    # Calculate signal statistics
    metrics = client.get_signal_metrics(
        provider="ibkr_primary",
        symbol="SPY",
        signal_name="momentum_signal",
        hours_back=24
    )
```

## Migration

The signals table is created via Alembic migration:

```bash
# Run migration
alembic upgrade head

# Verify table creation
psql -d marketdata -c "\d signals"
```

## Compression and Retention

- **Hot Tier**: 30 days (uncompressed)
- **Cold Tier**: Compressed after 30 days
- **Segment By**: `(provider, symbol, name)` for optimal compression
- **Chunk Size**: 7 days for balanced query performance

## Monitoring

### Key Metrics to Monitor

1. **Write Performance**
   - `store_signals_write_latency_seconds` - Should be < 100ms p95
   - `store_signals_written_total` - Track throughput

2. **Storage Health**
   - Table size growth
   - Compression ratio
   - Index usage

3. **Query Performance**
   - Latest signals query latency
   - Time-range query performance

### Grafana Dashboard Queries

```sql
-- Signals write rate
rate(store_signals_written_total[5m])

-- Write latency
histogram_quantile(0.95, rate(store_signals_write_latency_seconds_bucket[5m]))

-- Storage size
SELECT pg_size_pretty(pg_total_relation_size('signals'));
```

## Best Practices

1. **Batch Writes**: Use batch sizes of 100-1000 for optimal performance
2. **Idempotent Replays**: System handles duplicate signals gracefully
3. **Time-based Queries**: Leverage TimescaleDB time partitioning
4. **Signal Naming**: Use consistent naming conventions (e.g., `signal_type_timestamp`)
5. **Metadata**: Keep metadata lightweight for better compression

## Troubleshooting

### Common Issues

1. **High Write Latency**
   - Check batch sizes (use larger batches for high volume)
   - Monitor database connection pool
   - Verify TimescaleDB configuration

2. **Storage Growth**
   - Monitor compression policies
   - Check for data retention policies
   - Verify chunk size configuration

3. **Query Performance**
   - Ensure proper indexing
   - Use time-based query filters
   - Monitor query execution plans

### Debug Queries

```sql
-- Check table size
SELECT pg_size_pretty(pg_total_relation_size('signals'));

-- Check compression status
SELECT * FROM timescaledb_information.compression_stats
WHERE hypertable_name = 'signals';

-- Check chunk information
SELECT * FROM timescaledb_information.chunks
WHERE hypertable_name = 'signals';
```
